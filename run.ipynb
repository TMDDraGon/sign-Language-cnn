{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 05:52:30.659695: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'asl_alphabet_train'\n",
    "\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir + '/*/*.jpg'), shuffle=False)\n",
    "image_count = len(list_ds)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=True)\n",
    "\n",
    "class_names = np.array(sorted([item.name for item in os.scandir(data_dir)]))\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The total number of images in the dataset is {image_count}.\")\n",
    "print(f\"The number of different classes is {num_classes}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "img_height = 200\n",
    "img_width = 200\n",
    "channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splitting into training and validation sets\n",
    "val_size = int(image_count * 0.2)\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(file_path):\n",
    "    # Load the image\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=channel)\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "\n",
    "    # Data augmentation\n",
    "    img = tf.image.random_flip_left_right(img)  # Randomly flip the image left to right\n",
    "    img = tf.image.random_flip_up_down(img)  # Randomly flip the image upside down\n",
    "    img = tf.image.random_brightness(img, max_delta=0.1)  # Randomly adjust the brightness\n",
    "    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)  # Randomly adjust the contrast\n",
    "\n",
    "    # # Rescale pixel values\n",
    "    img /= 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2] == class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x: (preprocess_image(x), get_label(x)),\n",
    "                        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.map(lambda x: (preprocess_image(x), get_label(x)),\n",
    "                    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "val_ds = val_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(val_ds.take(2)))\n",
    "\n",
    "# Access the label of the first example\n",
    "first_label = image[0]\n",
    "\n",
    "plt.imshow(first_label, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add the layers to the model with the specified input shape\n",
    "model.add(Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(img_height, img_width, channel), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Metric to monitor\n",
    "    patience=3,           # Number of epochs to wait for improvement\n",
    "    restore_best_weights=True  # Restore model weights to those that achieved the best value of the monitored metric\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]  # Include early stopping callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0, max(np.max(history.history['loss']), np.max(history.history['val_loss']))])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(val_ds)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Validation Loss:\", evaluation[0])\n",
    "print(\"Validation Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store true labels and predictions\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "# Iterate over the test dataset to extract true labels and predictions\n",
    "for images, labels in test_ds:\n",
    "    true_labels.extend(np.argmax(labels, axis=1))  # Convert one-hot encoded labels to categorical labels\n",
    "    predictions.extend(np.argmax(model.predict(images), axis=1))  # Get predictions\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, predictions))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(confusion_matrix(true_labels, predictions), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"my_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
